# ğŸš€ **API de PrevisÃ£o de CotaÃ§Ãµes - LSTM**

[![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?style=for-the-badge&logo=tensorflow)](https://tensorflow.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)](https://docker.com)
[![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-red?style=for-the-badge&logo=prometheus)](https://prometheus.io)
[![Grafana](https://img.shields.io/badge/Grafana-Dashboard-orange?style=for-the-badge&logo=grafana)](https://grafana.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

---

## ğŸ“‹ **Ãndice**

- [VisÃ£o Geral e MotivaÃ§Ã£o](#visÃ£o-geral-e-motivaÃ§Ã£o)
- [Principais Funcionalidades](#principais-funcionalidades)
- [DemonstraÃ§Ã£o RÃ¡pida](#demonstraÃ§Ã£o-rÃ¡pida)
- [AplicaÃ§Ã£o Hospedada](#aplicaÃ§Ã£o-hospedada)
- [VÃ­deo Explicativo](#vÃ­deo-explicativo)
- [Exemplo de ExecuÃ§Ã£o do Treinamento](#exemplo-de-execuÃ§Ã£o-do-treinamento)
- [Exemplo de SaÃ­da do Treinamento](#exemplo-de-saÃ­da-do-treinamento)
- [Exemplo de Request/Response da API](#exemplo-de-requestresponse-da-api)
- [Arquitetura do Projeto](#arquitetura-do-projeto)
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [ExecuÃ§Ã£o e Deploy](#execuÃ§Ã£o-e-deploy)
- [Deploy na AWS](#deploy-na-aws)
- [Treinamento dos Modelos](#treinamento-dos-modelos)
- [DocumentaÃ§Ã£o da API](#documentaÃ§Ã£o-da-api)
- [Observabilidade e Monitoramento](#observabilidade-e-monitoramento)
- [LimitaÃ§Ãµes e Responsabilidades](#limitaÃ§Ãµes-e-responsabilidades)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [LicenÃ§a e ContribuiÃ§Ã£o](#licenÃ§a-e-contribuiÃ§Ã£o

# VisÃ£o Geral e MotivaÃ§Ã£o

Sistema avanÃ§ado de previsÃ£o de preÃ§os de aÃ§Ãµes da B3 utilizando redes neurais LSTM (Long Short-Term Memory). A API REST fornece previsÃµes do preÃ§o de fechamento para o prÃ³ximo dia Ãºtil, baseada em dados histÃ³ricos de 3 anos e anÃ¡lise de sÃ©ries temporais com observabilidade completa.

## ğŸ¯ **VisÃ£o Geral**

### **CaracterÃ­sticas Principais**

- ğŸ§  **Modelos LSTM** individuais por ativo com arquitetura de 3 camadas
- ğŸ“Š **PrevisÃµes em tempo real** via API REST com FastAPI
- ğŸ’¾ **Cache inteligente** com SQLite e fallback automÃ¡tico
- ï¿½ **MÃ©tricas de performance** (MAE, RMSE, MAPE) persistidas
- ï¿½ **Observabilidade completa** com Prometheus + Grafana
- ï¿½  **Deploy containerizado** com Docker Compose
- ï¿½ **Versionamento de modelos** com retreinamento dinÃ¢mico
- âš¡ **Middleware de mÃ©tricas** para monitoramento em tempo real

### **Stack TecnolÃ³gica**

| Componente | Tecnologia | VersÃ£o | PropÃ³sito |
|------------|------------|--------|-----------|
| **API Framework** | FastAPI | Latest | REST API e documentaÃ§Ã£o automÃ¡tica |
| **ML Framework** | TensorFlow/Keras | 2.x | Redes neurais LSTM |
| **Data Processing** | Pandas + NumPy | Latest | ManipulaÃ§Ã£o de dados financeiros |
| **Data Source** | yfinance | 0.2.36 | Yahoo Finance API |
| **Database** | SQLite | Built-in | Cache local e persistÃªncia |
| **Monitoring** | Prometheus | Latest | Coleta de mÃ©tricas |
| **Visualization** | Grafana | Latest | Dashboards e alertas |
| **Containerization** | Docker + Compose | Latest | OrquestraÃ§Ã£o de serviÃ§os |
| **Preprocessing** | scikit-learn | Latest | NormalizaÃ§Ã£o e mÃ©tricas |

# Principais Funcionalidades

## **Funcionalidades Core**

### ğŸ”® **PrevisÃ£o de PreÃ§os**

- Prediz o **preÃ§o de fechamento** do prÃ³ximo dia Ãºtil
- Utiliza **60 dias** de histÃ³rico como entrada (look-back window)
- NormalizaÃ§Ã£o automÃ¡tica com **MinMaxScaler**

### ğŸ“Š **AnÃ¡lise HistÃ³rica**

- PrevisÃµes retrospectivas dos Ãºltimos N dias Ãºteis
- ComparaÃ§Ã£o entre **preÃ§o real vs predito**
- ValidaÃ§Ã£o da performance do modelo

### ğŸ“ˆ **MÃ©tricas de AvaliaÃ§Ã£o**

- **MAE** (Mean Absolute Error)
- **RMSE** (Root Mean Square Error)
- **MAPE** (Mean Absolute Percentage Error)

## **Ativos Suportados**

| Ticker | Empresa | Setor | Status |
|--------|---------|-------|--------|
| **VALE3.SA** | Vale S.A. | MineraÃ§Ã£o | âœ… Ativo |
| **PETR4.SA** | Petrobras PN | PetrÃ³leo e GÃ¡s | âœ… Ativo |
| **ITSA4.SA** | ItaÃºsa PN | Holding Financeira | âœ… Ativo |
| **MGLU3.SA** | Magazine Luiza ON | Varejo | âœ… Ativo |
| **TAEE11.SA** | Taesa UNT | Energia ElÃ©trica | âœ… Ativo |

> **Nota**: Todos os modelos sÃ£o treinados individualmente com dados histÃ³ricos de 3 anos e janela de lookback de 60 dias.

# DemonstraÃ§Ã£o RÃ¡pida

## **AplicaÃ§Ã£o Hospedada**
>
> - **AplicaÃ§Ã£o:** http://56.125.194.131:8000/docs
> - **Grafana:** http://56.125.194.131:3000/

## **VÃ­deo Explicativo**

**ğŸ¬ Assista ao vÃ­deo completo:** [API de PrevisÃ£o de CotaÃ§Ãµes com LSTM - DemonstraÃ§Ã£o Completa](https://youtu.be/qwVbdNO-BjU?si=h6QF_cmVnHEgJpJX)

## **Exemplo de ExecuÃ§Ã£o do Treinamento**

```bash
# Treinamento com parÃ¢metros padrÃ£o
python src/app/train_lstm.py

# SaÃ­da esperada:
ğŸ¤– Iniciando processo de treinamento de modelos LSTM...
ğŸ“ Nova versÃ£o detectada: v2. Salvando em: /path/to/v2

--- Processando ticker: VALE3.SA (Epochs: 100, Batch: 32) ---
Dados carregados: 782 registros
SequÃªncias criadas: 722 amostras
Modelo LSTM construÃ­do.
Treinamento iniciado...
Epoch 45/100 - Loss: 0.0023 - Val_Loss: 0.0031
Early stopping triggered
MÃ©tricas VALE3.SA: MAE=1.23
Artefatos e mÃ©tricas da v2 salvos para VALE3.SA.
âœ… Pipeline completo para VALE3.SA em /path/to/v2

--- Processando ticker: PETR4.SA (Epochs: 100, Batch: 32) ---
[... processo similar para outros tickers ...]
```

## **Exemplo de SaÃ­da do Treinamento**

```
--- Processando ticker: VALE3.SA ---
Dados carregados: 782 registros
SequÃªncias criadas: 722 amostras
Treinamento iniciado...
Epoch 45/100 - Loss: 0.0023 - Val_Loss: 0.0031
Early stopping triggered
MÃ©tricas finais:
â”œâ”€â”€ MAE: 1.23
â”œâ”€â”€ RMSE: 1.67
â””â”€â”€ MAPE: 2.45%
âœ… Pipeline completo para VALE3.SA executado com sucesso!
```

## **Exemplo de Request/Response da API**

### **Request**

```bash
curl -X GET "http://localhost:8000/cotacao/previsao/VALE3?versao=v1" \
     -H "accept: application/json"
```

### **Response**

```json
{
  "symbol": "VALE3.SA",
  "name": "VALE3",
  "predicted_price": 61.47,
  "prediction_date": "2024-12-26",
  "MAE": 1.23,
  "RMSE": 1.67,
  "MAPE": 2.45
}
```

# Arquitetura do Projeto

## ğŸ—ï¸ **Arquitetura TÃ©cnica**

### **VisÃ£o Geral da Arquitetura**

```mermaid
graph TB
    subgraph "Client Layer"
        Client[Client Applications]
    end
    
    subgraph "API Gateway"
        FastAPI[FastAPI Application<br/>Port: 8000]
        Auth[Authentication & Validation]
        Middleware[Prometheus Middleware]
    end
    
    subgraph "Business Logic"
        PredService[Prediction Service]
        DataLoader[Data Loader Service]
    end
    
    subgraph "ML Infrastructure"
        ModelRegistry[Model Registry]
        LSTMModels[LSTM Models]
        Scalers[MinMax Scalers]
    end
    
    subgraph "Data Layer"
        SQLiteCache[(SQLite Cache)]
        YahooAPI[Yahoo Finance API]
    end
    
    subgraph "Observability Stack"
        Prometheus[Prometheus Server<br/>Port: 9090]
        Grafana[Grafana Dashboard<br/>Port: 3000]
        Metrics[Application Metrics]
    end
    
    subgraph "Containerization"
        Docker[Docker Engine]
        Compose[Docker Compose]
    end
    
    Client --> FastAPI
    FastAPI --> Auth
    Auth --> PredService
    FastAPI --> Middleware
    
    PredService --> ModelRegistry
    PredService --> DataLoader
    
    ModelRegistry --> LSTMModels
    ModelRegistry --> Scalers
    
    DataLoader --> SQLiteCache
    SQLiteCache -.->|Cache Miss| YahooAPI
    
    Middleware --> Metrics
    Metrics --> Prometheus
    Prometheus --> Grafana
    
    classDef clientLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef apiLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef businessLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef mlLayer fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef dataLayer fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef obsLayer fill:#f1f8e9,stroke:#689f38,stroke-width:2px
    classDef containerLayer fill:#e8eaf6,stroke:#283593,stroke-width:2px
    
    class Client clientLayer
    class FastAPI,Auth,Middleware apiLayer
    class PredService,DataLoader businessLayer
    class ModelRegistry,LSTMModels,Scalers mlLayer
    class SQLiteCache,YahooAPI dataLayer
    class Prometheus,Grafana,Metrics obsLayer
    class Docker,Compose containerLayer
```

### **Componentes Principais**

#### **1. FastAPI Application** (`src/app/main.py`)

- **Framework**: FastAPI com Uvicorn
- **Middleware**: Prometheus metrics collection
- **DocumentaÃ§Ã£o**: Swagger UI automÃ¡tico
- **CORS**: Configurado para desenvolvimento

#### **2. Prediction Service** (`src/app/services/`)

- **Responsabilidade**: OrquestraÃ§Ã£o de previsÃµes
- **Carregamento**: Modelos e scalers do disco
- **FormataÃ§Ã£o**: Tickers para padrÃ£o Yahoo Finance (.SA)
- **ValidaÃ§Ã£o**: Dados de entrada e saÃ­da

#### **3. Data Layer** (`src/app/data/`)

- **DataLoader**: Download e cache de dados
- **SQLite**: Cache local com fallback automÃ¡tico
- **Yahoo Finance**: Fonte primÃ¡ria de dados
- **PerÃ­odo**: 3 anos de histÃ³rico (configurÃ¡vel)

#### **4. LSTM Models** (`src/app/models/`)

- **RegressaoLSTM**: Classe principal do modelo
- **Arquitetura**: 3 camadas LSTM + Dropout
- **PersistÃªncia**: Keras (.keras) + Joblib (.jobjob)
- **MÃ©tricas**: CÃ¡lculo automÃ¡tico de MAE, RMSE, MAPE

### **Fluxo de Dados**

```mermaid
sequenceDiagram
    participant Client as Client Application
    participant API as FastAPI Gateway
    participant Auth as Request Validator
    participant Service as Prediction Service
    participant Registry as Model Registry
    participant Cache as SQLite Cache
    participant External as Yahoo Finance API
    participant Model as LSTM Model

    Client->>+API: POST /cotacao/previsao/{ticker}
    API->>+Auth: Validate Request Parameters
    Auth->>-API: Validation Result
    
    API->>+Service: Process Prediction Request
    Service->>+Registry: Load Model & Scaler
    Registry->>-Service: Model Artifacts
    
    Service->>+Cache: Query Historical Data
    alt Cache Hit
        Cache->>Service: Return Cached Data
    else Cache Miss
        Cache->>+External: Fetch Market Data
        External->>-Cache: OHLCV Data
        Cache->>Service: Return Fresh Data
    end
    
    Service->>Service: Preprocess Data<br/>(Normalize & Create Sequences)
    Service->>+Model: Execute Inference
    Model->>-Service: Price Prediction
    
    Service->>Service: Calculate Metrics & Confidence
    Service->>-API: Formatted Response
    API->>-Client: JSON Response with Prediction

    Note over Cache, External: Fallback Strategy
    Note over Service, Model: 60-day Lookback Window
    Note over API, Client: Include Performance Metrics
```

### **EstratÃ©gia de Cache**

```mermaid
flowchart TD
    Request[Data Request] --> CacheCheck{SQLite Cache<br/>Lookup}
    
    CacheCheck -->|Cache Hit| ValidateData{Data Freshness<br/>Validation}
    CacheCheck -->|Cache Miss| ExternalAPI[Yahoo Finance API]
    
    ValidateData -->|Fresh Data| ReturnCached[Return Cached Data]
    ValidateData -->|Stale Data| ExternalAPI
    
    ExternalAPI --> RateLimit{Rate Limiting<br/>Check}
    RateLimit -->|Within Limits| FetchData[Fetch Market Data]
    RateLimit -->|Rate Limited| BackoffRetry[Exponential Backoff<br/>& Retry]
    
    BackoffRetry --> RateLimit
    FetchData --> ProcessData[Data Validation<br/>& Transformation]
    ProcessData --> UpdateCache[Update SQLite Cache]
    UpdateCache --> ReturnFresh[Return Fresh Data]
    
    ReturnCached --> Complete[Request Complete]
    ReturnFresh --> Complete
    
    subgraph "Cache Layer"
        CacheCheck
        ValidateData
        UpdateCache
    end
    
    subgraph "External Integration"
        ExternalAPI
        RateLimit
        FetchData
        BackoffRetry
    end
    
    subgraph "Data Processing"
        ProcessData
        ReturnCached
        ReturnFresh
    end
    
    classDef cacheNodes fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef externalNodes fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    classDef processNodes fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    
    class CacheCheck,ValidateData,UpdateCache cacheNodes
    class ExternalAPI,RateLimit,FetchData,BackoffRetry externalNodes
    class ProcessData,ReturnCached,ReturnFresh processNodes
```

# InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

## **PrÃ©-requisitos**

| Requisito | VersÃ£o MÃ­nima | Recomendado | ObservaÃ§Ãµes |
|-----------|---------------|-------------|-------------|
| **Python** | 3.11+ | 3.11+ | Compatibilidade com TensorFlow |
| **RAM** | 4GB | 8GB+ | Para treinamento de modelos |
| **Armazenamento** | 2GB | 5GB+ | Modelos + dados histÃ³ricos |
| **Docker** | 20.10+ | Latest | Para deploy containerizado |
| **Docker Compose** | 2.0+ | Latest | OrquestraÃ§Ã£o de serviÃ§os |

## **InstalaÃ§Ã£o Local (Desenvolvimento)**

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd tech4

# 2. Crie um ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# 3. Instale as dependÃªncias
pip install -r requirements.txt

# 4. Crie a estrutura de diretÃ³rios
mkdir -p src/app/modelos_treinados_lstm/v1
mkdir -p src/app/dados

# 5. Execute o treinamento inicial (obrigatÃ³rio)
python src/app/train_lstm.py

# 6. Inicie a API
python src/app/main.py
```

## **InstalaÃ§Ã£o com Docker (ProduÃ§Ã£o)**

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd tech4

# 2. Build e execuÃ§Ã£o completa
docker-compose up -d --build

# 3. Verificar status dos serviÃ§os
docker-compose ps

# 4. Logs em tempo real
docker-compose logs -f api
```

## **VerificaÃ§Ã£o da InstalaÃ§Ã£o**

```bash
# Health check da API
curl http://localhost:8000/docs

# Teste de previsÃ£o
curl http://localhost:8000/cotacao/previsao/VALE3

# MÃ©tricas Prometheus
curl http://localhost:8000/metrics

# Dashboard Grafana
# Acesse: http://localhost:3000 (admin/admin)
```

## **ConfiguraÃ§Ãµes de Ambiente**

#### **VariÃ¡veis de Ambiente**

```bash
# .env file
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO
YAHOO_FINANCE_TIMEOUT=30
MODEL_CACHE_TTL=3600
PROMETHEUS_ENABLED=true
GRAFANA_ADMIN_PASSWORD=secure_password
```

#### **Docker Compose Override**

```yaml
# docker-compose.override.yml
version: "3.9"
services:
  api:
    environment:
      - LOG_LEVEL=DEBUG
      - YAHOO_FINANCE_TIMEOUT=60
    volumes:
      - ./logs:/app/logs
  
  grafana:
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    ports:
      - "3001:3000"  # Porta alternativa
```

# ExecuÃ§Ã£o e Deploy

## **ExecuÃ§Ã£o Local (Desenvolvimento)**

```bash
# MÃ©todo 1: Usando o script principal
python src/app/main.py

# MÃ©todo 2: Usando uvicorn diretamente
uvicorn src.app.main:app --host 0.0.0.0 --port 8000 --reload

# MÃ©todo 3: Com configuraÃ§Ãµes customizadas
HOST=0.0.0.0 PORT=8080 python src/app/main.py
```

## **ExecuÃ§Ã£o com Docker**

#### **OpÃ§Ã£o 1: Stack Completa (Recomendado)**
```bash
# Inicia todos os serviÃ§os (API + Prometheus + Grafana)
docker-compose up -d

# Verifica status dos containers
docker-compose ps

# Logs em tempo real
docker-compose logs -f

# Para serviÃ§os especÃ­ficos
docker-compose logs -f api
docker-compose logs -f grafana
docker-compose logs -f prometheus
```

#### **OpÃ§Ã£o 2: Apenas API**
```bash
# Build da imagem
docker build -t fastapi-stock-api .

# ExecuÃ§Ã£o simples
docker run -p 8000:8000 fastapi-stock-api

# ExecuÃ§Ã£o com volumes (persistÃªncia)
docker run -p 8000:8000 \
  -v $(pwd)/src/app/dados:/app/src/app/dados \
  -v $(pwd)/src/app/modelos_treinados_lstm:/app/src/app/modelos_treinados_lstm \
  fastapi-stock-api
```

## **Health Checks e Monitoramento**

```bash
# Health check da API
curl -f http://localhost:8000/docs || exit 1

# VerificaÃ§Ã£o de mÃ©tricas
curl -s http://localhost:8000/metrics | grep http_requests_total

# Status dos modelos
curl http://localhost:8000/cotacao/previsao/VALE3 | jq '.MAE'

# Logs estruturados
docker-compose logs api | grep ERROR

# Monitoramento de recursos
docker stats fastapi-stock-api
```

## **Troubleshooting**

#### **Problemas Comuns**

| Problema | Sintoma | SoluÃ§Ã£o |
|----------|---------|---------|
| **Modelo nÃ£o encontrado** | HTTP 500 | Execute `python src/app/train_lstm.py` |
| **Dados desatualizados** | PrevisÃµes antigas | Verifique conexÃ£o com Yahoo Finance |
| **Alta latÃªncia** | Timeout nas requests | Otimize cache ou aumente recursos |
| **Grafana nÃ£o carrega** | Dashboard vazio | Verifique configuraÃ§Ã£o do Prometheus |

#### **Comandos de Debug**

```bash
# Verificar logs detalhados
docker-compose logs -f --tail=100 api

# Entrar no container para debug
docker-compose exec api bash

# Verificar modelos treinados
ls -la src/app/modelos_treinados_lstm/v*/

# Testar conexÃ£o com Yahoo Finance
python -c "import yfinance as yf; print(yf.download('VALE3.SA', period='1d'))"

# Verificar mÃ©tricas do Prometheus
curl -s http://localhost:9090/api/v1/query?query=up
```

# Deploy na AWS

A aplicaÃ§Ã£o foi hospedada na **AWS Free Tier** utilizando uma instÃ¢ncia **EC2 t3.micro** com **Ubuntu 22.04 LTS**, demonstrando como deployar um sistema de ML em produÃ§Ã£o com recursos limitados.

## **Infraestrutura Utilizada**

| Componente | EspecificaÃ§Ã£o           | ObservaÃ§Ãµes |
|------------|-------------------------|-------------|
| **InstÃ¢ncia** | EC2 t3.micro            | 1 vCPU, 1GB RAM, Free Tier elegÃ­vel |
| **Sistema Operacional** | Ubuntu 22.04 LTS        | AMI oficial da Canonical |
| **Armazenamento** | 30GB gp3 SSD            | Volume EBS |
| **Rede** | VPC padrÃ£o + Elastic IP | IP pÃºblico fixo |
| **ContainerizaÃ§Ã£o** | Docker + Docker Compose | OrquestraÃ§Ã£o de serviÃ§os |

## **Arquitetura de Deploy**

```mermaid 
graph TB
    subgraph "AWS Cloud"
        EC2[EC2 t3.micro<br/>Ubuntu 22.04]
        EIP[Elastic IP]
        SG[Security Group<br/>Ports: 22, 8000, 3000, 9090]
        EBS[EBS 30GB SSD]
    end
    
    subgraph "AplicaÃ§Ã£o"
        Docker[Docker Engine]
        API[FastAPI:8000]
        Grafana[Grafana:3000]
        Prometheus[Prometheus:9090]
        SQLite[SQLite DB]
    end
    
    Users[UsuÃ¡rios] --> EIP
    EIP --> EC2
    EC2 --> SG
    EC2 --> EBS
    EC2 --> Docker
    Docker --> API
    Docker --> Grafana
    Docker --> Prometheus
    API --> SQLite
    
    classDef aws fill:#ff9900,stroke:#232f3e,stroke-width:2px,color:#fff
    classDef app fill:#146eb4,stroke:#232f3e,stroke-width:2px,color:#fff
    
    class EC2,EIP,SG,EBS aws
    class Docker,API,Grafana,Prometheus,SQLite app
```

## **OtimizaÃ§Ãµes para t3.micro**
- **Swap de 7GB** configurado para compensar limitaÃ§Ã£o de RAM
- **Restart automÃ¡tico** dos containers em caso de falha
- **Health checks** configurados para monitoramento

## **Endpoints DisponÃ­veis**

```
ğŸ“Š API Principal:        http://elastic-ip:8000
ğŸ“š DocumentaÃ§Ã£o:         http://elastic-ip:8000/docs
ğŸ“ˆ Dashboard Grafana:    http://elastic-ip:3000
ğŸ” MÃ©tricas Prometheus:  http://elastic-ip:9090
```

## **Custos (Free Tier)**

| Recurso | Custo Mensal |
|---------|--------------|
| **EC2 t3.micro** | $0 (750h grÃ¡tis) |
| **EBS 8GB** | $0 (30GB grÃ¡tis) |
| **Elastic IP** | $0 |
| **Data Transfer** | $0 (15GB grÃ¡tis) |
| **Total** | **$0/mÃªs** |

# Treinamento dos Modelos

## **Processo de Treinamento**

```bash
# Executa o pipeline completo de treinamento
python src/app/train_lstm.py
```

## **Pipeline de Treinamento**

```mermaid
flowchart TD
    Start(("InÃ­cio do Treinamento")) --> VersionCheck["Version Management<br/>Detecta prÃ³xima versÃ£o<br/>(v1, v2, v3...)"]
    VersionCheck --> DataCollection["Data Collection<br/>Yahoo Finance API<br/>3 Years Historical Data<br/>OHLCV + Volume"]
    DataCollection --> CacheStorage["Cache Storage<br/>SQLite Database<br/>Local Persistence<br/>Fallback Strategy"]
    CacheStorage --> DataValidation["Data Validation<br/>Missing Values Check<br/>Outlier Detection<br/>Data Quality Assurance"]
    DataValidation --> DataPrep["Data Preprocessing<br/>MinMax Normalization<br/>Sequence Generation<br/>60-day Lookback Window"]
    DataPrep --> DataSplit["Dataset Split<br/>Training: 70%<br/>Validation: 15%<br/>Test: 15%"]
    DataSplit --> ModelInit["Model Initialization<br/>LSTM Architecture<br/>3 Layers + Dropout<br/>Adam Optimizer"]
    ModelInit --> Training["Model Training<br/>Epochs: 100 (configurable)<br/>Batch Size: 32 (configurable)<br/>Early Stopping: 10 patience"]
    Training --> Evaluation["Model Evaluation<br/>MAE, RMSE, MAPE<br/>Performance Metrics<br/>Test Set Validation"]
    Evaluation --> QualityCheck{"Quality Gate<br/>MAPE < 10%?<br/>RMSE Reasonable?"}
    QualityCheck -->|Pass| Persistence["Artifact Persistence"]
    QualityCheck -->|Fail| Retrain["Hyperparameter Tuning<br/>Architecture Adjustment"]
    Retrain --> Training

    Persistence --> ModelArtifact["Model File<br/>modelo_lstm_{ticker}.keras<br/>TensorFlow SavedModel"]
    Persistence --> ScalerArtifact["Scaler File<br/>scaler_lstm_{ticker}.joblib<br/>MinMaxScaler State"]
    Persistence --> MetricsArtifact["Metrics File<br/>metrics_lstm_{ticker}.json<br/>Performance Metrics"]
    Persistence --> DatabasePersist["Database Persistence<br/>SQLite Metrics Storage<br/>Version Tracking"]

    ModelArtifact --> Complete(("Pipeline Complete<br/>Ready for Inference"))
    ScalerArtifact --> Complete
    MetricsArtifact --> Complete
    DatabasePersist --> Complete

    subgraph "Data Pipeline"
        DataCollection
        CacheStorage
        DataValidation
        DataPrep
        DataSplit
    end

    subgraph "ML Pipeline"
        ModelInit
        Training
        Evaluation
        QualityCheck
        Retrain
    end

    subgraph "Artifact Management"
        Persistence
        ModelArtifact
        ScalerArtifact
        MetricsArtifact
        DatabasePersist
    end

    classDef startEnd fill:#e8f5e8,stroke:#4caf50,stroke-width:3px
    classDef dataNodes fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    classDef mlNodes fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    classDef artifactNodes fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    classDef decisionNodes fill:#ffebee,stroke:#f44336,stroke-width:2px
    
    class Start,Complete startEnd
    class DataCollection,CacheStorage,DataValidation,DataPrep,DataSplit dataNodes
    class ModelInit,Training,Evaluation,Retrain mlNodes
    class Persistence,ModelArtifact,ScalerArtifact,MetricsArtifact,DatabasePersist artifactNodes
    class QualityCheck decisionNodes
```

## **Arquitetura da Rede Neural LSTM**

**Arquitetura LSTM utilizada:**

- **Input Layer:** SequÃªncia de preÃ§os normalizados (shape: batch_size, 60, 1)
- **LSTM Layer 1:** 50 unidades, retorna sequÃªncias, ativaÃ§Ã£o tanh
- **Dropout Layer 1:** taxa 0.2
- **LSTM Layer 2:** 50 unidades, nÃ£o retorna sequÃªncias, ativaÃ§Ã£o tanh
- **Dropout Layer 2:** taxa 0.2
- **Dense Layer 1:** 25 unidades, ativaÃ§Ã£o ReLU
- **Dense Layer 2:** 1 unidade, ativaÃ§Ã£o linear (regressÃ£o)
- **DenormalizaÃ§Ã£o:** MinMaxScaler.inverse_transform
- **SaÃ­da:** PreÃ§o previsto do prÃ³ximo dia Ãºtil (R$)


## **ConfiguraÃ§Ãµes de Treinamento**

| ParÃ¢metro | Valor PadrÃ£o | ConfigurÃ¡vel | DescriÃ§Ã£o |
|-----------|--------------|--------------|-----------|
| **Epochs** | 100 | âœ… Via API | NÃºmero mÃ¡ximo de Ã©pocas |
| **Batch Size** | 32 | âœ… Via API | Tamanho do lote de treinamento |
| **Learning Rate** | 0.001 | âŒ Fixo | Taxa de aprendizado do Adam |
| **Early Stopping** | 10 epochs | âŒ Fixo | PaciÃªncia para parada antecipada |
| **Validation Split** | 15% | âŒ Fixo | Porcentagem para validaÃ§Ã£o |
| **Test Split** | 15% | âŒ Fixo | Porcentagem para teste |
| **Lookback Window** | 60 dias | âŒ Fixo | Janela de dados histÃ³ricos |
| **Dropout Rate** | 0.2 | âŒ Fixo | Taxa de dropout para regularizaÃ§Ã£o |

## **Versionamento de Modelos**

O sistema implementa versionamento automÃ¡tico de modelos:

```bash
src/app/modelos_treinados_lstm/
â”œâ”€â”€ v1/                          # Primeira versÃ£o
â”‚   â”œâ”€â”€ modelo_lstm_VALE3.SA.keras
â”‚   â”œâ”€â”€ scaler_lstm_VALE3.SA.joblib
â”‚   â””â”€â”€ metrics_lstm_VALE3.SA.json
â”œâ”€â”€ v2/                          # Segunda versÃ£o (apÃ³s retreinamento)
â”‚   â”œâ”€â”€ modelo_lstm_VALE3.SA.keras
â”‚   â”œâ”€â”€ scaler_lstm_VALE3.SA.joblib
â”‚   â””â”€â”€ metrics_lstm_VALE3.SA.json
â””â”€â”€ v3/                          # Terceira versÃ£o
    â””â”€â”€ ...
```

## **Retreinamento via API**

```bash
# Retreinamento com parÃ¢metros customizados
curl -X POST "http://localhost:8000/cotacao/retreinar?epochs=50&batch=16"

# Resposta:
{
  "status": "Treinamento iniciado em segundo plano"
}

# Monitoramento via logs
docker-compose logs -f api | grep "Pipeline completo"
```

# DocumentaÃ§Ã£o da API

## **Base URL**: `http://localhost:8000`

### **ğŸ“Š DocumentaÃ§Ã£o Interativa**

- **Swagger UI**: `http://localhost:8000/docs` - Interface interativa completa
- **ReDoc**: `http://localhost:8000/redoc` - DocumentaÃ§Ã£o alternativa
- **OpenAPI Schema**: `http://localhost:8000/openapi.json` - Schema JSON

---

### **1. PrevisÃ£o Individual**

ObtÃ©m a previsÃ£o do preÃ§o de fechamento para o prÃ³ximo dia Ãºtil.

```http
GET /cotacao/previsao/{acao}?versao={versao}
```

**ParÃ¢metros:**
- `acao` (path, obrigatÃ³rio): CÃ³digo da aÃ§Ã£o (`VALE3`, `PETR4`, `ITSA4`, `MGLU3`, `TAEE11`)
- `versao` (query, opcional): VersÃ£o do modelo (`v1`, `v2`, etc.) - padrÃ£o: `v1`

**Exemplo de Request:**

```bash
curl -X GET "http://localhost:8000/cotacao/previsao/VALE3?versao=v1" \
     -H "accept: application/json"
```

**Exemplo de Response:**

```json
{
  "symbol": "VALE3.SA",
  "name": "VALE3",
  "predicted_price": 61.47,
  "prediction_date": "2024-12-26",
  "MAE": 1.23,
  "RMSE": 1.67,
  "MAPE": 2.45
}
```

---

### **2. PrevisÃ£o HistÃ³rica**

ObtÃ©m previsÃµes retrospectivas para anÃ¡lise de performance.

```http
GET /cotacao/historico/{acao}?versao={versao}
```

**ParÃ¢metros:**
- `acao` (path, obrigatÃ³rio): CÃ³digo da aÃ§Ã£o
- `versao` (query, opcional): VersÃ£o do modelo - padrÃ£o: `v1`

**Exemplo de Request:**

```bash
curl -X GET "http://localhost:8000/cotacao/historico/VALE3?versao=v1" \
     -H "accept: application/json"
```

**Exemplo de Response:**

```json
[
  {
    "symbol": "VALE3.SA",
    "name": "VALE3",
    "predicted_price": 61.20,
    "prediction_date": "2024-12-25",
    "MAE": 1.23,
    "RMSE": 1.67,
    "MAPE": 2.45
  },
  {
    "symbol": "VALE3.SA",
    "name": "VALE3",
    "predicted_price": 60.98,
    "prediction_date": "2024-12-24",
    "MAE": 1.23,
    "RMSE": 1.67,
    "MAPE": 2.45
  }
]
```

---

### **3. Retreinamento de Modelos**

Inicia o retreinamento de todos os modelos em background.

```http
POST /cotacao/retreinar?epochs={epochs}&batch={batch_size}
```

**ParÃ¢metros:**
- `epochs` (query, opcional): NÃºmero de Ã©pocas - padrÃ£o: `100`
- `batch` (query, opcional): Tamanho do batch - padrÃ£o: `32`

**Exemplo de Request:**

```bash
curl -X POST "http://localhost:8000/cotacao/retreinar?epochs=50&batch=16" \
     -H "accept: application/json"
```

**Exemplo de Response:**

```json
{
  "status": "Treinamento iniciado em segundo plano"
}
```

---

### **4. MÃ©tricas Prometheus**

Endpoint para coleta de mÃ©tricas pelo Prometheus.

```http
GET /metrics
```

**Exemplo de Response:**

```
# HELP http_requests_total Total de requisiÃ§Ãµes HTTP
# TYPE http_requests_total counter
http_requests_total{method="GET",endpoint="/cotacao/previsao/VALE3",status="200"} 42.0

# HELP http_request_duration_seconds LatÃªncia das requisiÃ§Ãµes HTTP
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{endpoint="/cotacao/previsao/VALE3",le="0.1"} 35.0
http_request_duration_seconds_bucket{endpoint="/cotacao/previsao/VALE3",le="0.25"} 40.0
http_request_duration_seconds_bucket{endpoint="/cotacao/previsao/VALE3",le="0.5"} 42.0
http_request_duration_seconds_bucket{endpoint="/cotacao/previsao/VALE3",le="+Inf"} 42.0
http_request_duration_seconds_sum{endpoint="/cotacao/previsao/VALE3"} 8.2
http_request_duration_seconds_count{endpoint="/cotacao/previsao/VALE3"} 42.0
```

---

### **CÃ³digos de Status HTTP**

| CÃ³digo | DescriÃ§Ã£o | Exemplo |
|--------|-----------|---------|
| `200` | Sucesso | PrevisÃ£o retornada com sucesso |
| `404` | NÃ£o encontrado | Ativo nÃ£o suportado ou versÃ£o inexistente |
| `422` | ParÃ¢metros invÃ¡lidos | Ticker invÃ¡lido ou parÃ¢metros malformados |
| `500` | Erro interno | Modelo nÃ£o encontrado, dados insuficientes |

### **Tratamento de Erros**

```json
{
  "detail": "Pasta 'v99' nÃ£o encontrada no servidor."
}
```

# Observabilidade e Monitoramento

## **Stack de Monitoramento**

| Componente | Porta | UsuÃ¡rio | Senha | PropÃ³sito |
|------------|-------|---------|-------|-----------|
| **Grafana** | 3000 | `admin` | `admin` | Dashboards e visualizaÃ§Ã£o |
| **Prometheus** | 9090 | - | - | Coleta e armazenamento de mÃ©tricas |
| **FastAPI Metrics** | 8000/metrics | - | - | Endpoint de mÃ©tricas da aplicaÃ§Ã£o |

## **MÃ©tricas Coletadas**

#### **MÃ©tricas HTTP (Prometheus)**

```python
# Contador de requisiÃ§Ãµes por endpoint
http_requests_total{method, endpoint, status}

# Histograma de latÃªncia por endpoint
http_request_duration_seconds{endpoint}

# Exemplos de queries PromQL
rate(http_requests_total[5m])                    # Taxa de requisiÃ§Ãµes por segundo
histogram_quantile(0.95, http_request_duration_seconds_bucket)  # LatÃªncia P95
```

#### **MÃ©tricas de NegÃ³cio**

```python
# MÃ©tricas especÃ­ficas da aplicaÃ§Ã£o (implementaÃ§Ã£o futura)
model_prediction_accuracy{ticker, version}       # AcurÃ¡cia por modelo
model_inference_duration{ticker}                 # Tempo de inferÃªncia
cache_hit_ratio{data_source}                    # Taxa de acerto do cache
yahoo_finance_api_calls_total{status}           # Chamadas para API externa
```

## **ConfiguraÃ§Ã£o do Prometheus**

```yaml
# prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'fastapi-stock-api'
    static_configs:
      - targets: ['api:8000']
    scrape_interval: 5s
    metrics_path: '/metrics'
    scrape_timeout: 10s
```

## **Dashboards Grafana**

#### **Dashboard Principal - API Performance**

```json
{
  "dashboard": {
    "title": "FastAPI Stock Prediction API",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time P95",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95 Latency"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"4..|5..\"}[5m])",
            "legendFormat": "{{status}} errors"
          }
        ]
      }
    ]
  }
}
```

#### **Dashboard de Modelos ML**

- **AcurÃ¡cia por Ticker**: ComparaÃ§Ã£o de MAE, RMSE, MAPE
- **Tempo de InferÃªncia**: LatÃªncia por modelo
- **Uso de Cache**: Hit/miss ratio por fonte de dados
- **Qualidade dos Dados**: Freshness e completude


## **Logs Estruturados**

#### **ConfiguraÃ§Ã£o de Logging**

```python
# src/app/logger/logger.py
import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
    
    def log_prediction(self, ticker: str, price: float, latency: float):
        self.logger.info(json.dumps({
            "event": "prediction_made",
            "ticker": ticker,
            "predicted_price": price,
            "latency_ms": latency * 1000,
            "timestamp": datetime.utcnow().isoformat()
        }))
    
    def log_error(self, error: str, context: dict = None):
        self.logger.error(json.dumps({
            "event": "error_occurred",
            "error": error,
            "context": context or {},
            "timestamp": datetime.utcnow().isoformat()
        }))
```

#### **Exemplos de Logs**

```json
// PrevisÃ£o bem-sucedida
{
  "event": "prediction_made",
  "ticker": "VALE3.SA",
  "predicted_price": 61.47,
  "latency_ms": 245.3,
  "timestamp": "2024-12-26T10:30:00Z"
}

// Erro de modelo
{
  "event": "error_occurred", 
  "error": "Model not found for ticker INVALID.SA",
  "context": {
    "ticker": "INVALID.SA",
    "version": "v1",
    "endpoint": "/cotacao/previsao/INVALID"
  },
  "timestamp": "2024-12-26T10:31:00Z"
}

// Cache miss
{
  "event": "cache_miss",
  "ticker": "PETR4.SA",
  "data_source": "yahoo_finance",
  "fetch_duration_ms": 1250.7,
  "timestamp": "2024-12-26T10:32:00Z"
}
```

#### **Comandos de Monitoramento**

```bash
# Verificar mÃ©tricas em tempo real
watch -n 5 'curl -s http://localhost:8000/metrics | grep http_requests_total'

# Monitorar logs de erro
docker-compose logs -f api | grep ERROR

# Verificar status dos containers
docker-compose ps

# Monitorar recursos do sistema
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"

# Testar conectividade com Prometheus
curl -s http://localhost:9090/api/v1/query?query=up | jq '.data.result'

# Verificar dashboards do Grafana
curl -s -u admin:admin http://localhost:3000/api/dashboards/home
```

# LimitaÃ§Ãµes e Responsabilidades

## **LimitaÃ§Ãµes TÃ©cnicas**

#### **ğŸ“Š Dados e Modelos**

| LimitaÃ§Ã£o | DescriÃ§Ã£o | Impacto | MitigaÃ§Ã£o PossÃ­vel |
|-----------|-----------|---------|-------------------|
| **PerÃ­odo HistÃ³rico** | Limitado a 3 anos de dados | Pode nÃ£o capturar ciclos longos | Expandir para 5-10 anos |
| **FrequÃªncia de Dados** | Apenas dados diÃ¡rios (EOD) | NÃ£o captura movimentos intraday | Implementar dados de alta frequÃªncia |
| **Universo de Ativos** | Restrito a 5 aÃ§Ãµes da B3 | Cobertura limitada do mercado | Expandir para mais setores |
| **Fonte Ãšnica** | DependÃªncia do Yahoo Finance | Ponto Ãºnico de falha | Implementar mÃºltiplas fontes |
| **Features Limitadas** | Apenas preÃ§os histÃ³ricos | Ignora fundamentalistas e sentimento | Adicionar indicadores tÃ©cnicos e fundamentalistas |

#### **ğŸ§  Machine Learning**

| LimitaÃ§Ã£o | DescriÃ§Ã£o | Impacto | SoluÃ§Ã£o Recomendada |
|-----------|-----------|---------|-------------------|
| **Arquitetura Simples** | LSTM bÃ¡sico sem ensemble | Menor robustez | Implementar ensemble de modelos |
| **Sem Retreinamento AutomÃ¡tico** | Modelos ficam desatualizados | DegradaÃ§Ã£o da performance | Pipeline de retreinamento automÃ¡tico |
| **ValidaÃ§Ã£o Simples** | Sem walk-forward analysis | Overfitting temporal | Implementar validaÃ§Ã£o temporal |
| **Sem AnÃ¡lise de Regime** | NÃ£o detecta mudanÃ§as de mercado | Performance inconsistente | Detectores de mudanÃ§a de regime |
| **Sem Incerteza** | NÃ£o fornece intervalos de confianÃ§a | DecisÃµes sem contexto de risco | Implementar Bayesian LSTM |

#### **âš¡ Performance e Escalabilidade**

| Aspecto | LimitaÃ§Ã£o Atual | Impacto | SoluÃ§Ã£o |
|---------|----------------|---------|---------|
| **LatÃªncia** | 200-500ms por previsÃ£o | UX degradada | Cache de previsÃµes, otimizaÃ§Ã£o de modelo |
| **ConcorrÃªncia** | Single-threaded | NÃ£o suporta alta carga | Load balancing, async processing |
| **Cache** | Sem TTL automÃ¡tico | Dados podem ficar stale | Implementar cache inteligente |
| **Escalabilidade** | Single-instance | LimitaÃ§Ã£o de throughput | Arquitetura distribuÃ­da |
| **MemÃ³ria** | Carregamento de todos os modelos | Alto uso de RAM | Lazy loading, model serving |

## **LimitaÃ§Ãµes Financeiras e RegulatÃ³rias**

#### **âŒ O que este sistema NÃƒO Ã©:**

```
ğŸš« AVISOS IMPORTANTES

âŒ NÃƒO Ã© consultoria financeira registrada na CVM
âŒ NÃƒO substitui anÃ¡lise profissional qualificada  
âŒ NÃƒO garante lucros ou performance futura
âŒ NÃƒO considera anÃ¡lise fundamentalista
âŒ NÃƒO Ã© um sistema de trading automatizado
âŒ NÃƒO considera fatores macroeconÃ´micos
âŒ NÃƒO analisa notÃ­cias ou eventos corporativos
âŒ NÃƒO considera liquidez ou volume de negociaÃ§Ã£o
```

#### **âœ… O que este sistema Ã‰:**

```
âœ… PROPÃ“SITOS VÃLIDOS

âœ… Ferramenta educacional para aprender ML em finanÃ§as
âœ… Prova de conceito tÃ©cnica de LSTM em sÃ©ries temporais
âœ… Sistema de apoio Ã  decisÃ£o (nÃ£o decisÃ£o final)
âœ… CÃ³digo aberto auditÃ¡vel e modificÃ¡vel
âœ… Plataforma para experimentaÃ§Ã£o e pesquisa
âœ… Base para desenvolvimento de sistemas mais robustos
âœ… DemonstraÃ§Ã£o de arquitetura de ML em produÃ§Ã£o
```

## **ğŸ›¡ï¸ Uso ResponsÃ¡vel e Ã‰tico**

#### **Diretrizes de Uso**

```
ğŸ¯ DIRETRIZES OBRIGATÃ“RIAS

ANTES de qualquer decisÃ£o de investimento:
â”œâ”€â”€ ğŸ“š Estude os fundamentos da empresa (balanÃ§os, DRE, fluxo de caixa)
â”œâ”€â”€ ğŸ“Š Analise o contexto macroeconÃ´mico e setorial
â”œâ”€â”€ ğŸ’° Defina seu perfil de risco e objetivos
â”œâ”€â”€ ğŸ¯ Diversifique adequadamente seus investimentos  
â”œâ”€â”€ ğŸ‘¨â€ğŸ’¼ Consulte profissionais qualificados (analistas, assessores)
â”œâ”€â”€ ğŸ“ˆ Use mÃºltiplas fontes de anÃ¡lise
â””â”€â”€ ğŸ§  Desenvolva seu prÃ³prio conhecimento financeiro

âš ï¸  NUNCA invista mais do que pode perder
âš ï¸  SEMPRE faÃ§a sua prÃ³pria anÃ¡lise independente
âš ï¸  Este sistema pode estar COMPLETAMENTE ERRADO
âš ï¸  Performance passada NÃƒO garante resultados futuras
âš ï¸  Mercados sÃ£o imprevisÃ­veis por natureza
```

#### **Responsabilidades do UsuÃ¡rio**

| Responsabilidade | DescriÃ§Ã£o | ImportÃ¢ncia |
|------------------|-----------|-------------|
| **Due Diligence** | Pesquisar independentemente cada investimento | ğŸ”´ CrÃ­tica |
| **GestÃ£o de Risco** | Definir stop-loss e position sizing | ğŸ”´ CrÃ­tica |
| **DiversificaÃ§Ã£o** | NÃ£o concentrar em poucos ativos | ğŸŸ¡ Alta |
| **EducaÃ§Ã£o ContÃ­nua** | Estudar mercados e investimentos | ğŸŸ¡ Alta |
| **Compliance** | Seguir regulamentaÃ§Ãµes aplicÃ¡veis | ğŸ”´ CrÃ­tica |


## **Disclaimer Legal**

```
ğŸ“‹ ISENÃ‡ÃƒO DE RESPONSABILIDADE

Este software Ã© fornecido "como estÃ¡", sem garantias de qualquer tipo.
Os desenvolvedores nÃ£o se responsabilizam por:

â€¢ Perdas financeiras decorrentes do uso das previsÃµes
â€¢ DecisÃµes de investimento baseadas nas informaÃ§Ãµes fornecidas  
â€¢ Falhas tÃ©cnicas ou indisponibilidade do sistema
â€¢ PrecisÃ£o ou atualidade dos dados e previsÃµes
â€¢ Conformidade com regulamentaÃ§Ãµes especÃ­ficas

O uso deste sistema implica na aceitaÃ§Ã£o integral destes termos.
```

# Estrutura do Projeto

```
tech4/
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ ğŸ“„ Dockerfile                  # Build da API
â”œâ”€â”€ ğŸ“„ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ README.md                   # Este arquivo
â”‚
â”œâ”€â”€ ğŸ“ src/app/                    # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ“„ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ ğŸ“„ train_lstm.py           # Pipeline de treinamento
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/controller/         # Controllers REST
â”‚   â”‚   â””â”€â”€ ğŸ“„ stocks.py           # Endpoints de aÃ§Ãµes
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ config/                 # ConfiguraÃ§Ãµes
â”‚   â”‚   â””â”€â”€ ğŸ“„ params.py           # ParÃ¢metros globais
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ data/                   # Camada de dados
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py      # Download e cache
â”‚   â”‚   â””â”€â”€ ğŸ“„ metrics_db.py       # MÃ©tricas do banco
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ dados/                  # Cache local
â”‚   â”‚   â””â”€â”€ ğŸ“„ dados_mercado.db    # SQLite database
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ logger/                 # Sistema de logs
â”‚   â”‚   â””â”€â”€ ğŸ“„ logger.py           # ConfiguraÃ§Ã£o de logging
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Modelos ML
â”‚   â”‚   â””â”€â”€ ğŸ“„ regression_lstm.py  # Classe LSTM
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ modelos_treinados_lstm/ # Artefatos ML
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ modelo_lstm_*.keras # Modelos treinados
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scaler_lstm_*.joblib# Scalers
â”‚   â”‚   â””â”€â”€ ğŸ“„ metrics_lstm_*.json # MÃ©tricas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ schemas/                # Modelos Pydantic
â”‚   â”‚   â””â”€â”€ ğŸ“„ prediction.py       # Schema de resposta
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ services/               # LÃ³gica de negÃ³cio
â”‚       â””â”€â”€ ğŸ“„ prediction_service.py # ServiÃ§o de previsÃ£o
â”‚
â”œâ”€â”€ ğŸ“ grafana/                    # ConfiguraÃ§Ã£o Grafana
â”‚   â”œâ”€â”€ ğŸ“ dashboards/             # Dashboards JSON
â”‚   â””â”€â”€ ğŸ“ provisioning/           # ConfiguraÃ§Ã£o automÃ¡tica
â”‚
â””â”€â”€ ğŸ“ prometheus/                 # ConfiguraÃ§Ã£o Prometheus
    â””â”€â”€ ğŸ“„ prometheus.yml          # ConfiguraÃ§Ã£o de scraping
```
